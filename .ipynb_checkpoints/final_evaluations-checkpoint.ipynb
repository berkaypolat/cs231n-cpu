{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook serves as extracting the final evaluation metrics for the trained models (both with pretrained weights nad unpretrained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as tfunc\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from PIL import Image\n",
    "import torch.nn.functional as func\n",
    "from util_datasets import GaussianNoise, UniformNoise\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.ranking import roc_auc_score\n",
    "import sklearn.metrics as metrics\n",
    "import random\n",
    "\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "torch.manual_seed(123)\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "\n",
    "class_names = ['No Finding', 'Enlarged Cardiomediastinum', 'Cardiomegaly', 'Lung Opacity', \n",
    "               'Lung Lesion', 'Edema', 'Consolidation', 'Pneumonia', 'Atelectasis', 'Pneumothorax', \n",
    "               'Pleural Effusion', 'Pleural Other', 'Fracture', 'Support Devices']\n",
    "\n",
    "imgtransResize = (320, 320)\n",
    "imgtransCrop = 224\n",
    "\n",
    "from trainer import CheXpertTrainer \n",
    "from chexpertClass import CheXpertData\n",
    "from denseNet121 import DenseNet121\n",
    "from utils import *\n",
    "# from ood_evaluate import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "# These utility functions are burrowed from utils.py in GPU VM instance\n",
    "####################\n",
    "\n",
    "def load_checkpoint_v2(checkpoint_path, model, optimizer, use_cuda):\n",
    "    if use_cuda:\n",
    "        state = torch.load(checkpoint_path)\n",
    "    else:\n",
    "        state = torch.load(checkpoint_path, map_location='cpu')\n",
    "   \n",
    "    model_state = state['state_dict']\n",
    "    optim_state = state['optimizer']\n",
    "    train_loss = state['train_losses']\n",
    "    eval_loss = state['eval_losses']\n",
    "    auroc_scores = state['aurocResults']\n",
    "    labels = state['labels']\n",
    "    scores = state['predictions']\n",
    "    model.load_state_dict(model_state)\n",
    "    optimizer.load_state_dict(optim_state)\n",
    "    \n",
    "    print('model loaded from %s' % checkpoint_path)\n",
    "    \n",
    "    return train_loss, eval_loss, labels, scores\n",
    "\n",
    "def evaluate_ood(data_loader, mode, model, device):\n",
    "    model.eval()\n",
    "    outPred = []\n",
    "    outGround = []\n",
    "    outConf = []\n",
    "    bxent = nn.BCELoss(reduction = 'mean')\n",
    "    \n",
    "    progress_bar = tqdm(data_loader)\n",
    "    \n",
    "    for i, (images,labels) in enumerate(progress_bar):\n",
    "        \n",
    "        if type(labels) == list:\n",
    "            #print(\"Chestnet being evaluated...\")\n",
    "            labels = torch.stack(labels).float().transpose(0,1).to(device)\n",
    "        #else:\n",
    "            #print(\"NIH being evaluated...\")\n",
    "\n",
    "\n",
    "        bs, c, h, w = images.size()\n",
    "        varInput = images.view(-1, c, h, w)\n",
    "        \n",
    "        outGround.append(labels.cpu().numpy())\n",
    "\n",
    "        if mode == 'confidence':\n",
    "            with torch.no_grad():\n",
    "                preds, confidence = model(varInput)\n",
    "                confidence = torch.sigmoid(confidence)\n",
    "                confidence = confidence.data.cpu().numpy()\n",
    "                outPred.append(preds.data.cpu().numpy())\n",
    "                outConf.append(confidence)\n",
    "\n",
    "        elif mode == 'confidence_scaling':\n",
    "            epsilon = 0.001  ##value needs to be determined (noise magnitude) \n",
    "\n",
    "            model.zero_grad()\n",
    "            varInput.requires_grad_()\n",
    "            \n",
    "            _,confidence = model(varInput)\n",
    "            confidence = torch.sigmoid(confidence)\n",
    "            loss = torch.mean(-torch.log(confidence))\n",
    "            loss.backward()\n",
    "\n",
    "            varInput = varInput - epsilon * torch.sign(varInput.grad)\n",
    "\n",
    "            preds,confidence = model(varInput)\n",
    "            confidence = torch.sigmoid(confidence)\n",
    "            confidence = confidence.data.cpu().numpy()\n",
    "            outPred.append(preds.data.cpu().numpy())\n",
    "            outConf.append(confidence)\n",
    "\n",
    "\n",
    "        elif mode == 'baseline':\n",
    "            with torch.no_grad():\n",
    "                pred, _ = model(varInput)\n",
    "                pred = pred.cpu().numpy()\n",
    "                outPred.append(pred)\n",
    "\n",
    "        elif mode == 'odin':\n",
    "            T = 1000  #this hyperparameter can also be experimeted\n",
    "            epsilon = 0.001\n",
    "\n",
    "            model.zero_grad()\n",
    "            pred,_ = model(varInput)\n",
    "            pred /= T\n",
    "            loss = bxent(pred, labels)\n",
    "            loss.backward()\n",
    "\n",
    "            varInput = varInput - epsilon * torch.sign(varInput.grad)\n",
    "            pred,_ = model(varInput)\n",
    "\n",
    "            #might need to take Sigmoid layer out from the model class for ODIN\n",
    "\n",
    "            pred = pred.data.cpu().numpy()\n",
    "            outPred.append(pred)\n",
    "            \n",
    "            \n",
    "    outPred = np.concatenate(outPred)\n",
    "    outGround = np.concatenate(outGround)\n",
    "    outConf = np.concatenate(outConf)\n",
    "    return outPred, outGround, outConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set:  223414\n",
      "Valid set:  234\n",
      "New train set:  221648\n",
      "New valid set:  1000\n",
      "New test set:  1000\n",
      "NIH train set:  4606\n",
      "NIH valid set:  1000\n"
     ]
    }
   ],
   "source": [
    "#TRANSFORM DATA SEQUENCE\n",
    "normalize = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "transformList = []\n",
    "#transformList.append(transforms.Resize(imgtransCrop))\n",
    "transformList.append(transforms.RandomResizedCrop(imgtransCrop))\n",
    "transformList.append(transforms.RandomHorizontalFlip())\n",
    "transformList.append(transforms.ToTensor())\n",
    "transformList.append(normalize)      \n",
    "transformSequence=transforms.Compose(transformList)\n",
    "\n",
    "#CheXpert dataset loading\n",
    "chex_datasetValid = CheXpertData('datasets/chexpert-small/CheXpert-v1.0-small/valid.csv',transformSequence, preload = True, policy=\"ones\")\n",
    "chex_datasetTrain = CheXpertData('datasets/chexpert-small/CheXpert-v1.0-small/train.csv',transformSequence, policy=\"ones\")\n",
    "print(\"Train set: \", len(chex_datasetTrain))\n",
    "print(\"Valid set: \", len(chex_datasetValid))\n",
    "datasetValid, datasetTrain = random_split(chex_datasetTrain, [766, len(chex_datasetTrain) - 766])\n",
    "chex_test, chex_train = random_split(datasetTrain, [1000, len(datasetTrain) - 1000])\n",
    "\n",
    "#split datasets into train,valid,test\n",
    "chex_valid = torch.utils.data.ConcatDataset([chex_datasetValid, datasetValid])\n",
    "print(\"New train set: \", len(chex_train))\n",
    "print(\"New valid set: \", len(chex_valid))\n",
    "print(\"New test set: \", len(chex_test))\n",
    "dataLoaderTrain = DataLoader(dataset=chex_train, batch_size=16, shuffle=True,  num_workers=1, pin_memory=True)\n",
    "dataLoaderValid = DataLoader(dataset=chex_valid, batch_size=16, shuffle=False,  num_workers=1, pin_memory=True)\n",
    "dataLoaderTest = DataLoader(dataset=chex_test, batch_size=16, shuffle=False,  num_workers=0, pin_memory=True)\n",
    "\n",
    "#NIH dataset loading\n",
    "nih_dataset = datasets.ImageFolder(root='datasets/nih-small/small', transform = transformSequence)\n",
    "nih_test, nih_train = random_split(nih_dataset, [1000, len(nih_dataset) - 1000])\n",
    "print(\"NIH train set: \", len(nih_train))\n",
    "print(\"NIH valid set: \", len(nih_test))\n",
    "dataLoaderNIH = DataLoader(dataset=nih_test, batch_size=16, shuffle=False,  num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation for the model with pretrained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded from checkpoints/epoch3.pth.tar\n"
     ]
    }
   ],
   "source": [
    "model = DenseNet121(len(class_names)).to(device)\n",
    "model = torch.nn.DataParallel(model).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.999), eps=1e-08, weight_decay=1e-5)\n",
    "checkpoint_path1 = 'checkpoints/epoch1.pth.tar'\n",
    "checkpoint_path2 = 'checkpoints/epoch2.pth.tar'\n",
    "checkpoint_path3 = 'checkpoints/epoch3.pth.tar'\n",
    "train_v1_loss, eval_v1_loss, labels_v1, preds_v1 = load_checkpoint_v2(checkpoint_path3, model, optimizer, use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [46:05<00:00, 37.65s/it]\n",
      "100%|██████████| 63/63 [46:10<00:00, 37.47s/it]\n"
     ]
    }
   ],
   "source": [
    "ind_scores, ind_gt, ind_conf = evaluate_ood(dataLoaderTest, 'confidence', model, device)\n",
    "ood_scores, _, ood_conf = evaluate_ood(dataLoaderNIH, 'confidence', model, device)\n",
    "\n",
    "ood_gt = np.zeros((ood_scores.shape[0], ood_scores.shape[1]))\n",
    "labels = np.concatenate([ind_gt, ood_gt])\n",
    "scores = np.concatenate([ind_scores, ood_scores])\n",
    "confidences = np.concatenate([ind_conf,ood_conf])\n",
    "ind_conf_labels = np.ones(ind_scores.shape[0])\n",
    "ood_conf_labels = np.zeros(ood_scores.shape[0])\n",
    "conf_labels = np.concatenate([ind_conf_labels,ood_conf_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Method: confidence\n",
      "TPR75 (lower is better):  0.9347499999999878\n",
      "Detection error (lower is better):  0.5\n",
      "Best threshold: 0.6241537928581238\n",
      "AUROC (higher is better):  0.274096\n",
      "AUPR_IN (higher is better):  0.3662906445791707\n",
      "AUPR_OUT (higher is better):  0.3681440388854611\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr = tpr76(ind_conf, ood_conf)\n",
    "detection_error, best_delta = detection(ind_conf, ood_conf)\n",
    "auroc = metrics.roc_auc_score(conf_labels, confidences)\n",
    "aupr_in = metrics.average_precision_score(conf_labels, confidences)\n",
    "aupr_out = metrics.average_precision_score(-1 * conf_labels + 1, 1 - confidences)\n",
    "\n",
    "print(\"\")\n",
    "print(\"Method: confidence\")\n",
    "print(\"TPR75 (lower is better): \", fpr)\n",
    "print(\"Detection error (lower is better): \", detection_error)\n",
    "print(\"Best threshold:\", best_delta)\n",
    "print(\"AUROC (higher is better): \", auroc)\n",
    "print(\"AUPR_IN (higher is better): \", aupr_in)\n",
    "print(\"AUPR_OUT (higher is better): \", aupr_out)\n",
    "        \n",
    "ranges = (np.min(confidences), np.max(confidences))\n",
    "sns.distplot(ind_conf.ravel(), hist_kws={'range': ranges}, kde=False, bins=50, norm_hist=True, label='In-distribution')\n",
    "sns.distplot(ood_conf.ravel(), hist_kws={'range': ranges}, kde=False, bins=50, norm_hist=True, label='Out-of-distribution')\n",
    "plt.xlabel('Total Confidence Distribution')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
